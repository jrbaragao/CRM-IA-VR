import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from datetime import datetime
import io
import base64
from openai import OpenAI
import plotly.express as px
import plotly.graph_objects as go
import os
import sqlite3

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="ğŸ“Š AnÃ¡lise de Notas Fiscais",
    page_icon="ğŸ“‹",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS customizado
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #007bff;
    }
    .success-box {
        background: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

def criar_banco_sqlite(df_cabecalho, df_itens):
    """Cria e configura o banco SQLite com os dados dos DataFrames"""
    conn = sqlite3.connect('notas_fiscais.db')
    
    # Ajustar nomes das colunas (remover espaÃ§os e caracteres especiais)
    df_cabecalho.columns = [col.replace(' ', '_').replace('/', '_').replace('(', '').replace(')', '') for col in df_cabecalho.columns]
    df_itens.columns = [col.replace(' ', '_').replace('/', '_').replace('(', '').replace(')', '') for col in df_itens.columns]
    
    # Converter DataFrames para SQLite
    df_cabecalho.to_sql('cabecalho', conn, if_exists='replace', index=False)
    df_itens.to_sql('itens', conn, if_exists='replace', index=False)
    
    # Mostrar estrutura das tabelas
    st.info("ğŸ“Š Estrutura das tabelas no banco SQLite:")
    
    # Estrutura da tabela cabecalho
    cursor = conn.cursor()
    cursor.execute("PRAGMA table_info(cabecalho)")
    colunas_cabecalho = cursor.fetchall()
    st.write("Tabela 'cabecalho':")
    for col in colunas_cabecalho:
        st.write(f"- {col[1]} ({col[2]})")
    
    # Estrutura da tabela itens
    cursor.execute("PRAGMA table_info(itens)")
    colunas_itens = cursor.fetchall()
    st.write("Tabela 'itens':")
    for col in colunas_itens:
        st.write(f"- {col[1]} ({col[2]})")
    
    return conn

def executar_query_sqlite(query, conn):
    """Executa uma query SQL no banco SQLite"""
    try:
        return pd.read_sql_query(query, conn)
    except Exception as e:
        st.error(f"âŒ Erro na query SQL: {str(e)}")
        return None

def processar_pergunta(pergunta, conn, client, df_cabecalho, df_itens):
    """Processa a pergunta do usuÃ¡rio e retorna a resposta"""
    try:
        # Preparar informaÃ§Ãµes sobre as colunas
        colunas_cabecalho = [col.replace(' ', '_').replace('/', '_').replace('(', '').replace(')', '') for col in df_cabecalho.columns]
        colunas_itens = [col.replace(' ', '_').replace('/', '_').replace('(', '').replace(')', '') for col in df_itens.columns]
        
        # Exemplos de dados
        exemplo_cabecalho = df_cabecalho.head(1).to_dict('records')[0]
        exemplo_itens = df_itens.head(1).to_dict('records')[0]
        
        # Primeiro, verificar se a pergunta precisa de SQL
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": f"""VocÃª Ã© um assistente especializado em anÃ¡lise de dados.
                Sua tarefa Ã© determinar se a pergunta do usuÃ¡rio precisa de uma consulta SQL ou nÃ£o.
                Responda APENAS com 'SQL' se precisar de consulta SQL, ou 'CHAT' se for uma pergunta geral.
                
                Contexto dos dados:
                Tabela 'cabecalho':
                - Colunas: {', '.join(colunas_cabecalho)}
                - Exemplo: {exemplo_cabecalho}
                
                Tabela 'itens':
                - Colunas: {', '.join(colunas_itens)}
                - Exemplo: {exemplo_itens}
                
                Exemplos:
                - "OlÃ¡" -> CHAT
                - "Como vai?" -> CHAT
                - "Qual o valor total?" -> SQL
                - "Mostre as notas" -> SQL"""},
                {"role": "user", "content": pergunta}
            ],
            max_tokens=10
        )
        
        tipo_resposta = response.choices[0].message.content.strip()
        
        if tipo_resposta == "CHAT":
            # Se for uma pergunta geral, responder diretamente
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": f"""VocÃª Ã© um assistente especializado em anÃ¡lise de notas fiscais.
                    VocÃª tem acesso aos seguintes dados:
                    
                    Tabela 'cabecalho':
                    - Colunas: {', '.join(colunas_cabecalho)}
                    - Exemplo: {exemplo_cabecalho}
                    
                    Tabela 'itens':
                    - Colunas: {', '.join(colunas_itens)}
                    - Exemplo: {exemplo_itens}
                    
                    Responda de forma amigÃ¡vel e profissional."""},
                    {"role": "user", "content": pergunta}
                ],
                max_tokens=500
            )
            
            return {
                "sql": None,
                "resultado": None,
                "resposta_formatada": response.choices[0].message.content
            }
        
        # Se precisar de SQL, continuar com o processamento normal
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": f"""VocÃª Ã© um especialista em SQL e anÃ¡lise de dados.
                Sua tarefa Ã© converter perguntas em portuguÃªs para comandos SQL.
                Use SQLite como banco de dados.
                
                Tabelas disponÃ­veis:
                
                1. Tabela 'cabecalho':
                - Colunas: {', '.join(colunas_cabecalho)}
                - Exemplo: {exemplo_cabecalho}
                
                2. Tabela 'itens':
                - Colunas: {', '.join(colunas_itens)}
                - Exemplo: {exemplo_itens}
                
                IMPORTANTE:
                1. Retorne APENAS o comando SQL, sem ```sql ou outras marcaÃ§Ãµes
                2. Use os nomes das colunas EXATAMENTE como mostrado acima (com underscores)
                3. Use aspas simples para strings
                4. Exemplo correto: SELECT VALOR_NOTA_FISCAL FROM cabecalho WHERE CHAVE_DE_ACESSO = '123'
                5. NÃƒO inclua ```sql no inÃ­cio ou fim da query"""},
                {"role": "user", "content": pergunta}
            ],
            max_tokens=500
        )
        
        # Extrair SQL gerado e limpar
        sql_query = response.choices[0].message.content.strip()
        # Remover ```sql se existir
        sql_query = sql_query.replace('```sql', '').replace('```', '').strip()
        
        # Executar query
        resultado = executar_query_sqlite(sql_query, conn)
        
        if resultado is not None:
            # Formatar resposta
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "VocÃª Ã© um especialista em anÃ¡lise de dados. Formate a resposta de forma clara e profissional."},
                    {"role": "user", "content": f"Formate esta resposta para o usuÃ¡rio: {resultado.to_string()}"}
                ],
                max_tokens=500
            )
            
            return {
                "sql": sql_query,
                "resultado": resultado,
                "resposta_formatada": response.choices[0].message.content
            }
        
    except Exception as e:
        st.error(f"âŒ Erro ao processar pergunta: {str(e)}")
        return None

# FunÃ§Ã£o principal
def main():
    # Header principal
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ“Š AnÃ¡lise Inteligente de Notas Fiscais</h1>
        <p>Upload, anÃ¡lise e chat inteligente com IA</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar com configuraÃ§Ãµes
    with st.sidebar:
        st.header("âš™ï¸ ConfiguraÃ§Ãµes")
        
        # Campo para API da OpenAI
        st.subheader("ğŸ¤– IntegraÃ§Ã£o OpenAI")
        openai_api_key = st.text_input(
            "API Key da OpenAI:",
            type="password",
            help="Cole sua API key da OpenAI para anÃ¡lises inteligentes e chat"
        )
        
        if openai_api_key:
            # Criar cliente OpenAI
            try:
                os.environ["OPENAI_API_KEY"] = openai_api_key
                client = OpenAI(api_key=openai_api_key)
                st.success("âœ… API OpenAI configurada! (GPT-4o)")
            except Exception as e:
                st.error(f"âŒ Erro ao configurar OpenAI: {str(e)}")
                client = None
        
        st.divider()
        
        # ConfiguraÃ§Ãµes do Chat
        st.subheader("ğŸ’¬ ConfiguraÃ§Ãµes do Chat")
        chat_ativado = st.checkbox("Ativar Chat Inteligente", value=True)
        
        if chat_ativado:
            max_memory_tokens = st.slider("MemÃ³ria do Chat (tokens):", 1000, 5000, 3000)
            st.info("ğŸ“Š O chat analisarÃ¡ os dados CSV que vocÃª carregar")
        else:
            max_memory_tokens = 3000  # Valor padrÃ£o quando desativado
        
        st.divider()
        
    # Upload de arquivos
    st.header("ğŸ“ Upload dos Arquivos")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“‹ CabeÃ§alhos das Notas Fiscais")
        arquivo_cabecalho = st.file_uploader(
            "Selecione o arquivo de cabeÃ§alhos (.csv)",
            type=['csv'],
            key="cabecalho"
        )
        
    with col2:
        st.subheader("ğŸ“¦ Itens das Notas Fiscais") 
        arquivo_itens = st.file_uploader(
            "Selecione o arquivo de itens (.csv)",
            type=['csv'],
            key="itens"
        )
    
    # Processamento dos arquivos
    if arquivo_cabecalho and arquivo_itens:
        
        # Carregando os dados
        with st.spinner("ğŸ”„ Carregando arquivos..."):
            try:
                df_cabecalho = pd.read_csv(arquivo_cabecalho)
                df_itens = pd.read_csv(arquivo_itens)
                
                # Criar banco SQLite
                conn = criar_banco_sqlite(df_cabecalho, df_itens)
                
                st.success("âœ… Arquivos carregados e banco SQLite criado com sucesso!")
                
            except Exception as e:
                st.error(f"âŒ Erro ao carregar arquivos: {str(e)}")
                return
        
        # InformaÃ§Ãµes bÃ¡sicas
        st.header("ğŸ“Š InformaÃ§Ãµes dos Datasets")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ğŸ“‹ Registros CabeÃ§alho", df_cabecalho.shape[0])
        with col2:
            st.metric("ğŸ“‹ Colunas CabeÃ§alho", df_cabecalho.shape[1])
        with col3:
            st.metric("ğŸ“¦ Registros Itens", df_itens.shape[0])
        with col4:
            st.metric("ğŸ“¦ Colunas Itens", df_itens.shape[1])
        
        # Preview dos dados
        st.header("ğŸ‘€ Preview dos Dados")
        
        tab1, tab2 = st.tabs(["ğŸ“‹ CabeÃ§alhos", "ğŸ“¦ Itens"])
        
        with tab1:
            st.dataframe(df_cabecalho.head(), use_container_width=True)
            
        with tab2:
            st.dataframe(df_itens.head(), use_container_width=True)

    # Chat Inteligente com dados carregados
    if openai_api_key and chat_ativado and 'conn' in locals() and 'client' in locals() and client is not None:
        st.header("ğŸ’¬ Chat Inteligente com Dados das Notas Fiscais")
        
        # Inicializar histÃ³rico do chat
        if "messages" not in st.session_state:
            st.session_state.messages = []
        
        # Mostrar histÃ³rico do chat
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # Input do usuÃ¡rio
        if prompt := st.chat_input("FaÃ§a sua pergunta sobre os dados das notas fiscais..."):
            # Adicionar mensagem do usuÃ¡rio
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # Processar pergunta
            with st.chat_message("assistant"):
                with st.spinner("ğŸ¤– Processando..."):
                    resultado = processar_pergunta(prompt, conn, client, df_cabecalho, df_itens)
                    
                    if resultado:
                        if resultado["sql"]:
                            # Se tiver SQL, mostrar o comando
                            st.code(resultado["sql"], language="sql")
                        
                        # Mostrar resultado formatado
                        st.markdown(resultado["resposta_formatada"])
                        
                        # Adicionar resposta ao histÃ³rico
                        mensagem = resultado["resposta_formatada"]
                        if resultado["sql"]:
                            mensagem = f"SQL gerado:\n```sql\n{resultado['sql']}\n```\n\nResposta:\n{resultado['resposta_formatada']}"
                        
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": mensagem
                        })
                    else:
                        st.error("âŒ NÃ£o foi possÃ­vel processar sua pergunta.")

# FunÃ§Ã£o removida - geraÃ§Ã£o de PDF nÃ£o Ã© mais necessÃ¡ria

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
    <p>ğŸ“Š AnÃ¡lise de Notas Fiscais | Desenvolvido com Streamlit e GPT-4o</p>
</div>
""", unsafe_allow_html=True)

if __name__ == "__main__":
    main() 