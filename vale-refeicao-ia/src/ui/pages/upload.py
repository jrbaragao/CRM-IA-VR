"""
P√°gina de upload de arquivos
"""

import streamlit as st
import pandas as pd
from pathlib import Path
from datetime import datetime
import os
import io
import json
import streamlit.components.v1 as components

from ..components import (
    render_upload_widget,
    render_alert,
    render_data_preview,
    render_metrics_row
)
from ...config.settings import settings
from ...utils.cloud_storage import storage_manager

def render():
    """Renderiza p√°gina de upload"""
    st.header("üì§ Upload de Dados")
    
    # Mostrar informa√ß√µes sobre storage
    storage_info = storage_manager.get_storage_info()
    if storage_info['using_gcs']:
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.warning(f"""
            ‚òÅÔ∏è **Cloud Storage Configurado** - Bucket: `{storage_info['bucket_name']}`
            
            ‚úÖ **Upload Direto ao GCS habilitado**
            """)
        
        # col2 intencionalmente sem conte√∫do: bot√£o "Arquivos Grandes?" removido
        
        # Debug - vamos descobrir de onde vem o limite
        if st.button("üîç Debug Upload Limits", help="Investigar de onde vem o limite real"):
            from ...utils.debug_upload import debug_upload_limits, create_test_file
            
            debug_upload_limits()
            create_test_file()

        # Garantir CORS do bucket para upload direto via navegador (executa uma vez)
        if not st.session_state.get('gcs_cors_configured'):
            if storage_manager.configure_bucket_cors():
                st.session_state['gcs_cors_configured'] = True
                st.info("CORS do bucket verificado/atualizado para upload direto.")

        st.divider()
        render_gcs_direct_upload_section(storage_info['bucket_name'])
        
    else:
        st.info("üíæ **Modo Local** - Limite de upload: **200MB** por arquivo")
    
    # Mostrar o fluxo completo com destaque visual
    st.markdown("""
    ### üìã Fluxo do Sistema:
    <div style='background-color: #e6f3ff; padding: 15px; border-radius: 10px; margin-bottom: 20px;'>
        <b>1. üì§ Upload</b> <span style='color: #667eea;'>(VOC√ä EST√Å AQUI)</span> ‚Üí 
        2. üîÑ Prepara√ß√£o de Dados ‚Üí 
        3. üóÉÔ∏è Banco de Dados ‚Üí 
        4. ü§ñ Agentes de IA
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("""
    Fa√ßa o upload das suas planilhas de dados. O sistema criar√° **tabelas din√¢micas** 
    automaticamente e os **agentes aut√¥nomos** identificar√£o as correla√ß√µes atrav√©s 
    dos prompts configurados.
    """)
    
    # Informa√ß√µes sobre o novo sistema
    with st.expander("‚ÑπÔ∏è Como funciona o novo sistema", expanded=False):
        st.markdown("""
        **üöÄ Sistema Inteligente e Flex√≠vel:**
        
        **üìä Tabelas Din√¢micas:**
        - Cada arquivo cria sua pr√≥pria tabela no banco
        - Estrutura adaptada automaticamente aos dados
        - Sem necessidade de esquema pr√©-definido
        
        **ü§ñ Correla√ß√µes Inteligentes:**
        - Agentes aut√¥nomos identificam rela√ß√µes entre tabelas
        - Prompts definem como correlacionar os dados
        - Chaves de correla√ß√£o definidas dinamicamente
        
        **üîÑ Processo Simplificado:**
        - Upload ‚Üí Tabela Din√¢mica ‚Üí Configura√ß√£o de Prompts ‚Üí An√°lise Aut√¥noma
        """)
    
    # Container para uploads
    st.subheader("üìÅ Selecione seus Arquivos de Dados")
    
    uploaded_files = st.file_uploader(
        "Fa√ßa upload dos seus arquivos de dados",
        type=['csv', 'xlsx', 'xls'],
        accept_multiple_files=True,
        key="data_files_upload",
        help="Cada arquivo ser√° processado e criar√° uma tabela din√¢mica no banco de dados"
    )
    
    if uploaded_files:
        # Processar todos os arquivos
        process_uploaded_files(uploaded_files)
    
    # Se√ß√£o de arquivos carregados
    if st.session_state.get('uploaded_files'):
        st.divider()
        display_uploaded_files()
        
        # Informa√ß√µes sobre pr√≥ximos passos
        st.divider()
        
        # Criar um alerta visual mais claro
        st.success("‚úÖ **Arquivos carregados com sucesso!**")
        
        # Instru√ß√µes claras com destaque visual
        with st.container():
            st.markdown("""
            ### üéØ **Pr√≥ximo Passo Obrigat√≥rio:**
            
            <div style='background-color: #f0f2f6; padding: 20px; border-radius: 10px; border-left: 5px solid #667eea; position: relative;'>
                <div style='position: absolute; left: -40px; top: 50%; transform: translateY(-50%); font-size: 30px; animation: bounce 2s infinite;'>
                    ‚¨ÖÔ∏è
                </div>
                <h4>üëâ Clique em <b>"üîÑ Prepara√ß√£o de Dados"</b> no menu lateral</h4>
                <p style='color: #666; margin: 5px 0;'>O menu est√° √† esquerda da tela</p>
                <p style='color: #d73502; font-weight: bold; margin: 10px 0 0 0;'>
                    ‚ö†Ô∏è N√£o use os bot√µes do navegador! Use o menu lateral do Streamlit.
                </p>
            </div>
            
            <style>
                @keyframes bounce {
                    0%, 100% { transform: translateY(-50%) translateX(0); }
                    50% { transform: translateY(-50%) translateX(-10px); }
                }
            </style>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            #### O que acontecer√° na pr√≥xima p√°gina:
            - ü§ñ O agente de IA processar√° e limpar√° os dados
            - üèóÔ∏è Criar√° tabelas din√¢micas no banco de dados
            - üìä Salvar√° permanentemente os dados
            - üìà Voc√™ ver√° logs em tempo real
            
            > **‚ö†Ô∏è Importante**: Os dados ainda N√ÉO foram salvos no banco. Voc√™ DEVE ir para "Prepara√ß√£o de Dados" para completar o processo.
            """)

def process_uploaded_files(files):
    """Processa todos os arquivos enviados com logs detalhados"""
    
    # Container de logs visuais
    log_container = st.empty()
    progress_bar = st.progress(0)
    
    logs = []
    
    def add_log(icon, message, type="info"):
        """Adiciona log visual"""
        logs.append(f"{icon} {message}")
        log_text = "\n".join(logs)
        
        if type == "error":
            log_container.error(log_text)
        elif type == "warning":
            log_container.warning(log_text)
        elif type == "success":
            log_container.success(log_text)
        else:
            log_container.info(log_text)
    
    try:
        if 'uploaded_files' not in st.session_state:
            st.session_state['uploaded_files'] = {}
        
        total_files = len(files)
        add_log("üìã", f"Iniciando processamento de {total_files} arquivo(s)...")
        
        for i, file in enumerate(files):
            try:
                add_log("üìÅ", f"**Arquivo {i+1}/{total_files}**: {file.name}")
                progress_bar.progress((i) / total_files)
                
                # Obter tamanho do arquivo
                add_log("üìè", f"Verificando tamanho do arquivo...")
                file.seek(0, 2)  # Ir para o final do arquivo
                file_size_bytes = file.tell()
                file_size_mb = file_size_bytes / (1024 * 1024)
                file.seek(0)  # Voltar ao in√≠cio
                
                add_log("‚úÖ", f"Tamanho: **{file_size_mb:.2f} MB** ({file_size_bytes:,} bytes)")
                
                # Verificar limite
                if file_size_mb > 30:
                    add_log("‚ö†Ô∏è", f"**ALERTA**: Arquivo > 30MB! Cloud Run pode rejeitar.", "warning")
                    add_log("üí°", "Solu√ß√£o: Use a vers√£o local ou divida o arquivo", "warning")
                    
                # Tentar salvar arquivo
                add_log("üíæ", f"Salvando arquivo no storage...")
                try:
                    file_content = file.read()
                    file.seek(0)  # Resetar para leitura do pandas
                    
                    add_log("‚òÅÔ∏è", f"Fazendo upload para Cloud Storage...")
                    
                    saved_path = storage_manager.upload_file(
                        file_content,
                        file.name,
                        folder="uploads"
                    )
                    
                    if not saved_path:
                        add_log("‚ùå", f"Erro ao salvar arquivo '{file.name}'", "error")
                        continue
                        
                    add_log("‚úÖ", f"Arquivo salvo: {saved_path}", "success")
                    
                except Exception as e:
                    add_log("‚ùå", f"**ERRO ao salvar**: {str(e)}", "error")
                    add_log("üîç", f"Tipo de erro: {type(e).__name__}", "error")
                    
                    if "413" in str(e) or "Payload" in str(e) or "too large" in str(e).lower():
                        add_log("üö®", f"**ERRO 413 (Payload Too Large)**", "error")
                        add_log("üìä", f"Arquivo {file.name}: {file_size_mb:.2f}MB", "error")
                        add_log("‚ö†Ô∏è", f"Limite do Cloud Run: ~32MB via HTTP", "error")
                        add_log("üí°", f"**SOLU√á√ÉO**: Use a vers√£o local:", "warning")
                        add_log("üíª", "```bash\ngit clone https://github.com/jrbaragao/CRM-IA-VR.git\ncd CRM-IA-VR/vale-refeicao-ia\nstreamlit run app.py\n```", "warning")
                    continue
                
                # Ler arquivo para obter metadados
                add_log("üìä", f"Lendo dados para an√°lise...")
                
                try:
                    if file.name.endswith('.csv'):
                        # Ler CSV com tratamento especial para aspas
                        df = pd.read_csv(file, quotechar='"', skipinitialspace=True)
                        # Remover aspas dos nomes das colunas se houver
                        df.columns = df.columns.str.strip('"').str.strip()
                    else:
                        df = pd.read_excel(file)
                    
                    add_log("‚úÖ", f"Dados lidos: {len(df)} linhas x {len(df.columns)} colunas")
                    
                except Exception as e:
                    add_log("‚ùå", f"Erro ao ler dados: {str(e)}", "error")
                    continue
                
                # Valida√ß√µes b√°sicas
                if df.empty:
                    add_log("‚ö†Ô∏è", f"Arquivo '{file.name}' est√° vazio", "warning")
                    continue
                
                # Armazenar no session state
                file_key = f"file_{i}_{file.name}"
                st.session_state['uploaded_files'][file_key] = {
                    'name': file.name,
                    'data': df,  # Mant√©m em mem√≥ria para preview
                    'file_path': saved_path,  # Caminho no storage
                    'file_size_mb': round(file_size_mb, 2),
                    'type': 'data',  # Todos s√£o dados agora
                    'uploaded_at': datetime.now(),
                    'rows': len(df),
                    'columns': len(df.columns),
                    'index_column': None  # Coluna de indexa√ß√£o
                }
                
                add_log("üéâ", f"**Arquivo processado com sucesso!**", "success")
                
            except Exception as e:
                add_log("‚ùå", f"**ERRO n√£o tratado**: {str(e)}", "error")
                add_log("üîç", f"Tipo de erro: {type(e).__name__}", "error")
                import traceback
                add_log("üìù", f"```\n{traceback.format_exc()}\n```", "error")
        
        progress_bar.progress(1.0)
        add_log("üèÅ", f"**Processamento conclu√≠do!**", "success")
        
        # Resumo final
        successful = len(st.session_state.get('uploaded_files', {}))
        add_log("üìä", f"**Total processado**: {successful}/{total_files} arquivo(s)", "success" if successful == total_files else "warning")
        
        # Preview e configura√ß√£o dos arquivos
        for file_key, file_info in st.session_state['uploaded_files'].items():
            if file_key.startswith('file_'):
                storage_icon = "‚òÅÔ∏è" if file_info.get('file_path', '').startswith('gs://') else "üíæ"
                with st.expander(f"üìä {file_info['name']} - {file_info.get('file_size_mb', 0)}MB {storage_icon} ({file_info['rows']} linhas, {file_info['columns']} colunas)", expanded=False):
                    # Preview dos dados
                    st.dataframe(file_info['data'].head(), use_container_width=True)
                    
                    # Sele√ß√£o de coluna de indexa√ß√£o
                    st.divider()
                    col1, col2 = st.columns([1, 1])
                    
                    with col1:
                        st.markdown("**üîë Configura√ß√£o de Indexa√ß√£o**")
                        use_index = st.checkbox(
                            "Definir coluna de indexa√ß√£o",
                            key=f"use_index_{file_key}",
                            help="Marque se deseja definir uma coluna como chave prim√°ria/√≠ndice para correla√ß√£o entre tabelas"
                        )
                    
                    with col2:
                        if use_index:
                            columns = list(file_info['data'].columns)
                            index_col = st.selectbox(
                                "Selecione a coluna de indexa√ß√£o:",
                                options=[''] + columns,
                                key=f"index_{file_key}",
                                help="Esta coluna ser√° usada como chave prim√°ria para relacionar com outras tabelas"
                            )
                            
                            # Atualizar no session state
                            if index_col:
                                st.session_state['uploaded_files'][file_key]['index_column'] = index_col
                                st.info(f"‚úÖ Coluna '{index_col}' definida como √≠ndice")
        
    except Exception as e:
        st.error(f"‚ùå Erro ao processar arquivos: {str(e)}")

def render_gcs_direct_upload_section(bucket_name: str):
    """Se√ß√£o para upload direto ao GCS via Signed URL (PUT) sem enviar arquivo ao servidor."""
    st.subheader("‚òÅÔ∏è Upload Direto ao Google Cloud Storage (Recomendado para >30MB)")

    # Gerar um nome de objeto √∫nico na sess√£o
    if 'gcs_pending_object' not in st.session_state:
        unique_id = f"{int(datetime.now().timestamp())}-{os.urandom(4).hex()}"
        st.session_state['gcs_pending_object'] = f"uploads/upload-{unique_id}"

    object_name = st.session_state['gcs_pending_object']

    # Gera Signed URL com content-type gen√©rico
    signed_url = storage_manager.generate_signed_upload_url(
        object_name,
        expiration_minutes=30,
        content_type="application/octet-stream"
    )

    gs_path = f"gs://{bucket_name}/{object_name}"
    st.info(f"Destino no GCS: {gs_path}")

    # Se Signed URL n√£o estiver dispon√≠vel, cria sess√£o resumable
    session_url = None
    if not signed_url:
        session_url = storage_manager.create_resumable_upload_session(object_name, "application/octet-stream")

    html = """
<div style=\"font-family: sans-serif;\">
  <input id=\"fileInput\" type=\"file\" accept=\".csv,.xlsx,.xls\" />
  <button id=\"btnUpload\">Enviar ao GCS</button>
  <div id=\"status\" style=\"margin-top:8px;color:#333\"></div>
</div>
<script>
  const btn = document.getElementById('btnUpload');
  const input = document.getElementById('fileInput');
  const statusEl = document.getElementById('status');
  const signedUrl = '__SIGNED_URL__';
  const resumableUrl = '__SESSION_URL__';
  btn.onclick = async () => {
    try {
      if (!input.files || input.files.length === 0) {
        statusEl.textContent = 'Selecione um arquivo primeiro';
        return;
      }
      const file = input.files[0];
      statusEl.textContent = 'Enviando...';
      if (signedUrl && signedUrl !== 'NONE') {
        const resp = await fetch(signedUrl, {
          method: 'PUT',
          headers: { 'Content-Type': 'application/octet-stream' },
          body: file
        });
        if (!resp.ok) {
          const text = await resp.text();
          statusEl.textContent = 'Falha no upload (Signed URL): ' + resp.status;
          const pre = document.createElement('pre');
          pre.textContent = text;
          statusEl.appendChild(pre);
          return;
        }
      } else if (resumableUrl && resumableUrl !== 'NONE') {
        // Upload resumable com um √∫nico chunk (envia todo arquivo)
        const resp = await fetch(resumableUrl, {
          method: 'PUT',
          headers: {
            'Content-Type': 'application/octet-stream',
            'Content-Range': 'bytes 0-' + (file.size - 1) + '/' + file.size
          },
          body: file
        });
        if (!(resp.ok || resp.status === 308)) {
          const text = await resp.text();
          statusEl.textContent = 'Falha no upload (Resumable): ' + resp.status;
          const pre = document.createElement('pre');
          pre.textContent = text;
          statusEl.appendChild(pre);
          return;
        }
      } else {
        statusEl.textContent = 'N√£o foi poss√≠vel iniciar upload (sem URL)';
        return;
      }
      statusEl.textContent = '‚úÖ Upload conclu√≠do: __GS_PATH__';
    } catch (e) {
      statusEl.textContent = 'Erro: ' + (e && (e.message || e))
    }
  };
</script>
    """
    html = html.replace('__SIGNED_URL__', signed_url or 'NONE')\
               .replace('__SESSION_URL__', session_url or 'NONE')\
               .replace('__GS_PATH__', gs_path)
    components.html(html, height=200)

    if st.button("üîÑ Verificar e processar arquivo do GCS"):
        process_gcs_uploaded_file(gs_path)

def process_gcs_uploaded_file(gcs_path: str):
    """L√™ arquivo do GCS e integra ao fluxo de arquivos carregados."""
    try:
        content = storage_manager.download_file(gcs_path)
        if content is None:
            st.error("N√£o foi poss√≠vel baixar arquivo do GCS.")
            return

        name = Path(gcs_path).name

        # Detecta tipo pelo sufixo
        if name.lower().endswith('.csv'):
            df = pd.read_csv(io.BytesIO(content))
        else:
            df = pd.read_excel(io.BytesIO(content))

        if 'uploaded_files' not in st.session_state:
            st.session_state['uploaded_files'] = {}

        file_key = f"gcs_{name}_{int(datetime.now().timestamp())}"
        st.session_state['uploaded_files'][file_key] = {
            'name': name,
            'data': df,
            'file_path': gcs_path,
            'file_size_mb': round(len(content) / (1024 * 1024), 2),
            'type': 'data',
            'uploaded_at': datetime.now(),
            'rows': len(df),
            'columns': len(df.columns),
            'index_column': None
        }

        st.success(f"‚úÖ Arquivo processado do GCS: {name}")
    except Exception as e:
        st.error(f"Erro ao processar arquivo do GCS: {e}")

def process_main_file(file):
    """Processa arquivo principal"""
    try:
        # Ler arquivo
        if file.name.endswith('.csv'):
            df = pd.read_csv(file)
        else:
            df = pd.read_excel(file)
        
        # Valida√ß√µes b√°sicas
        if 'MATRICULA' not in df.columns and 'matricula' not in df.columns and 'Matricula' not in df.columns:
            # Tentar identificar coluna de matr√≠cula
            possible_matricula_cols = [col for col in df.columns 
                                     if any(term in col.lower() 
                                           for term in ['matric', 'registro', 'cod', 'id'])]
            
            if possible_matricula_cols:
                render_alert(
                    f"Coluna MATRICULA n√£o encontrada. Poss√≠veis candidatas: {', '.join(possible_matricula_cols)}",
                    "warning"
                )
            else:
                render_alert(
                    "‚ö†Ô∏è Aten√ß√£o: Coluna MATRICULA n√£o encontrada. O sistema tentar√° identific√°-la automaticamente.",
                    "warning"
                )
        
        # Armazenar no session state
        if 'uploaded_files' not in st.session_state:
            st.session_state['uploaded_files'] = {}
        
        st.session_state['uploaded_files']['main'] = {
            'name': file.name,
            'data': df,
            'type': 'main',
            'upload_time': datetime.now(),
            'rows': len(df),
            'columns': len(df.columns)
        }
        
        # Mostrar preview
        render_data_preview(df, f"Preview: {file.name}")
        
        render_alert(f"‚úÖ Arquivo '{file.name}' carregado com sucesso!", "success")
        
    except Exception as e:
        render_alert(f"Erro ao processar arquivo: {str(e)}", "error")

def process_complementary_files(files):
    """Processa arquivos complementares"""
    if 'uploaded_files' not in st.session_state:
        st.session_state['uploaded_files'] = {}
    
    success_count = 0
    error_count = 0
    
    for file in files:
        try:
            # Ler arquivo
            if file.name.endswith('.csv'):
                # Ler CSV com tratamento especial para aspas
                df = pd.read_csv(file, quotechar='"', skipinitialspace=True)
                # Remover aspas dos nomes das colunas se houver
                df.columns = df.columns.str.strip('"').str.strip()
            else:
                df = pd.read_excel(file)
            
            # Armazenar
            file_key = f"comp_{file.name}"
            st.session_state['uploaded_files'][file_key] = {
                'name': file.name,
                'data': df,
                'type': 'complementary',
                'upload_time': datetime.now(),
                'rows': len(df),
                'columns': len(df.columns)
            }
            
            success_count += 1
            
        except Exception as e:
            error_count += 1
            st.error(f"Erro em '{file.name}': {str(e)}")
    
    if success_count > 0:
        render_alert(
            f"‚úÖ {success_count} arquivo(s) complementar(es) carregado(s) com sucesso!",
            "success"
        )
    
    if error_count > 0:
        render_alert(
            f"‚ùå {error_count} arquivo(s) com erro no processamento.",
            "error"
        )

def process_batch_files(files):
    """Processa m√∫ltiplos arquivos em lote"""
    if 'uploaded_files' not in st.session_state:
        st.session_state['uploaded_files'] = {}
    
    progress_bar = st.progress(0, text="Processando arquivos...")
    success_count = 0
    error_count = 0
    
    for idx, file in enumerate(files):
        try:
            # Atualizar progresso
            progress = (idx + 1) / len(files)
            progress_bar.progress(progress, text=f"Processando {file.name}...")
            
            # Ler arquivo
            if file.name.endswith('.csv'):
                # Ler CSV com tratamento especial para aspas
                df = pd.read_csv(file, quotechar='"', skipinitialspace=True)
                # Remover aspas dos nomes das colunas se houver
                df.columns = df.columns.str.strip('"').str.strip()
            else:
                df = pd.read_excel(file)
            
            # Determinar tipo (principal ou complementar)
            file_type = 'main' if idx == 0 else 'complementary'
            file_key = 'main' if file_type == 'main' else f"batch_{file.name}"
            
            # Armazenar
            st.session_state['uploaded_files'][file_key] = {
                'name': file.name,
                'data': df,
                'type': file_type,
                'upload_time': datetime.now(),
                'rows': len(df),
                'columns': len(df.columns)
            }
            
            success_count += 1
            
        except Exception as e:
            error_count += 1
            st.error(f"Erro em '{file.name}': {str(e)}")
    
    progress_bar.empty()
    
    # Mostrar resumo
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Total de Arquivos", len(files))
    with col2:
        st.metric("Sucesso", success_count, delta=None, delta_color="normal")
    with col3:
        st.metric("Erros", error_count, delta=None, delta_color="inverse" if error_count > 0 else "normal")

def display_uploaded_files():
    """Exibe resumo dos arquivos carregados"""
    st.subheader("üìÅ Arquivos Carregados")
    
    files_data = []
    total_rows = 0
    
    for key, file_info in st.session_state['uploaded_files'].items():
        files_data.append({
            'Nome': file_info['name'],
            'Tipo': 'Dados',  # Todos s√£o dados agora
            'Linhas': f"{file_info['rows']:,}",
            'Colunas': file_info['columns'],
            'Upload': file_info.get('uploaded_at', file_info.get('upload_time', datetime.now())).strftime('%H:%M:%S')
        })
        total_rows += file_info['rows']
    
    # Tabela de arquivos
    df_files = pd.DataFrame(files_data)
    st.dataframe(df_files, use_container_width=True, hide_index=True)
    
    # M√©tricas resumidas
    metrics = [
        {'label': 'Total de Arquivos', 'value': len(files_data)},
        {'label': 'Total de Registros', 'value': f"{total_rows:,}"},
        {'label': 'Tabelas a Criar', 'value': len(files_data)}
    ]
    
    render_metrics_row(metrics)
    
    # Op√ß√£o para remover arquivos
    with st.expander("üóëÔ∏è Gerenciar Arquivos"):
        files_to_remove = st.multiselect(
            "Selecione arquivos para remover:",
            options=[file_info['name'] for file_info in st.session_state['uploaded_files'].values()]
        )
        
        if files_to_remove and st.button("Remover Selecionados", type="secondary"):
            for key, file_info in list(st.session_state['uploaded_files'].items()):
                if file_info['name'] in files_to_remove:
                    del st.session_state['uploaded_files'][key]
            st.rerun()
