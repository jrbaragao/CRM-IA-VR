"""
PÃ¡gina de upload de arquivos
"""

import streamlit as st
import pandas as pd
from pathlib import Path
from datetime import datetime

from ..components import (
    render_upload_widget,
    render_alert,
    render_data_preview,
    render_metrics_row
)
from ...config.settings import settings
from ...utils.cloud_storage import storage_manager

def render():
    """Renderiza pÃ¡gina de upload"""
    st.header("ğŸ“¤ Upload de Dados")
    
    # Mostrar informaÃ§Ãµes sobre storage (simplificado)
    storage_info = storage_manager.get_storage_info()
    
    # Mostrar aviso sobre limite de tamanho
    limit_message = storage_manager.get_file_size_limit_message()
    
    if storage_info['is_cloud_run']:
        st.warning(f"""
        {limit_message}
        
        ğŸ’¡ **Dica**: Para trabalhos acadÃªmicos, use arquivos CSV menores ou teste localmente para arquivos maiores.
        """)
    else:
        st.info(limit_message)
    
    # Mostrar o fluxo completo com destaque visual
    st.markdown("""
    ### ğŸ“‹ Fluxo do Sistema:
    <div style='background-color: #e6f3ff; padding: 15px; border-radius: 10px; margin-bottom: 20px;'>
        <b>1. ğŸ“¤ Upload</b> <span style='color: #667eea;'>(VOCÃŠ ESTÃ AQUI)</span> â†’ 
        2. ğŸ”„ PreparaÃ§Ã£o de Dados â†’ 
        3. ğŸ—ƒï¸ Banco de Dados â†’ 
        4. ğŸ¤– Agentes de IA
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("""
    FaÃ§a o upload das suas planilhas de dados. O sistema criarÃ¡ **tabelas dinÃ¢micas** 
    automaticamente e os **agentes autÃ´nomos** identificarÃ£o as correlaÃ§Ãµes atravÃ©s 
    dos prompts configurados.
    """)
    
    # InformaÃ§Ãµes sobre o novo sistema
    with st.expander("â„¹ï¸ Como funciona o novo sistema", expanded=False):
        st.markdown("""
        **ğŸš€ Sistema Inteligente e FlexÃ­vel:**
        
        **ğŸ“Š Tabelas DinÃ¢micas:**
        - Cada arquivo cria sua prÃ³pria tabela no banco
        - Estrutura adaptada automaticamente aos dados
        - Sem necessidade de esquema prÃ©-definido
        
        **ğŸ¤– CorrelaÃ§Ãµes Inteligentes:**
        - Agentes autÃ´nomos identificam relaÃ§Ãµes entre tabelas
        - Prompts definem como correlacionar os dados
        - Chaves de correlaÃ§Ã£o definidas dinamicamente
        
        **ğŸ”„ Processo Simplificado:**
        - Upload â†’ Tabela DinÃ¢mica â†’ ConfiguraÃ§Ã£o de Prompts â†’ AnÃ¡lise AutÃ´noma
        """)
    
    # Container para uploads
    st.subheader("ğŸ“ Selecione seus Arquivos de Dados")
    
    uploaded_files = st.file_uploader(
        "FaÃ§a upload dos seus arquivos de dados",
        type=['csv', 'xlsx', 'xls'],
        accept_multiple_files=True,
        key="data_files_upload",
        help="Cada arquivo serÃ¡ processado e criarÃ¡ uma tabela dinÃ¢mica no banco de dados"
    )
    
    if uploaded_files:
        # Processar todos os arquivos
        process_uploaded_files(uploaded_files)
    
    # SeÃ§Ã£o de arquivos carregados
    if st.session_state.get('uploaded_files'):
        st.divider()
        display_uploaded_files()
        
        # InformaÃ§Ãµes sobre prÃ³ximos passos
        st.divider()
        
        # Criar um alerta visual mais claro
        st.success("âœ… **Arquivos carregados com sucesso!**")
        
        # InstruÃ§Ãµes claras com destaque visual
        with st.container():
            st.markdown("""
            ### ğŸ¯ **PrÃ³ximo Passo ObrigatÃ³rio:**
            
            <div style='background-color: #f0f2f6; padding: 20px; border-radius: 10px; border-left: 5px solid #667eea; position: relative;'>
                <div style='position: absolute; left: -40px; top: 50%; transform: translateY(-50%); font-size: 30px; animation: bounce 2s infinite;'>
                    â¬…ï¸
                </div>
                <h4>ğŸ‘‰ Clique em <b>"ğŸ”„ PreparaÃ§Ã£o de Dados"</b> no menu lateral</h4>
                <p style='color: #666; margin: 5px 0;'>O menu estÃ¡ Ã  esquerda da tela</p>
                <p style='color: #d73502; font-weight: bold; margin: 10px 0 0 0;'>
                    âš ï¸ NÃ£o use os botÃµes do navegador! Use o menu lateral do Streamlit.
                </p>
            </div>
            
            <style>
                @keyframes bounce {
                    0%, 100% { transform: translateY(-50%) translateX(0); }
                    50% { transform: translateY(-50%) translateX(-10px); }
                }
            </style>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            #### O que acontecerÃ¡ na prÃ³xima pÃ¡gina:
            - ğŸ¤– O agente de IA processarÃ¡ e limparÃ¡ os dados
            - ğŸ—ï¸ CriarÃ¡ tabelas dinÃ¢micas no banco de dados
            - ğŸ“Š SalvarÃ¡ permanentemente os dados
            - ğŸ“ˆ VocÃª verÃ¡ logs em tempo real
            
            > **âš ï¸ Importante**: Os dados ainda NÃƒO foram salvos no banco. VocÃª DEVE ir para "PreparaÃ§Ã£o de Dados" para completar o processo.
            """)

def process_uploaded_files(files):
    """Processa todos os arquivos enviados com logs detalhados"""
    
    # Container de logs visuais
    log_container = st.empty()
    progress_bar = st.progress(0)
    
    logs = []
    
    def add_log(icon, message, type="info"):
        """Adiciona log visual"""
        logs.append(f"{icon} {message}")
        log_text = "\n".join(logs)
        
        if type == "error":
            log_container.error(log_text)
        elif type == "warning":
            log_container.warning(log_text)
        elif type == "success":
            log_container.success(log_text)
        else:
            log_container.info(log_text)
    
    try:
        if 'uploaded_files' not in st.session_state:
            st.session_state['uploaded_files'] = {}
        
        total_files = len(files)
        add_log("ğŸ“‹", f"Iniciando processamento de {total_files} arquivo(s)...")
        
        for i, file in enumerate(files):
            try:
                add_log("ğŸ“", f"**Arquivo {i+1}/{total_files}**: {file.name}")
                progress_bar.progress((i) / total_files)
                
                # Obter tamanho do arquivo
                add_log("ğŸ“", f"Verificando tamanho do arquivo...")
                file.seek(0, 2)  # Ir para o final do arquivo
                file_size_bytes = file.tell()
                file_size_mb = file_size_bytes / (1024 * 1024)
                file.seek(0)  # Voltar ao inÃ­cio
                
                add_log("âœ…", f"Tamanho: **{file_size_mb:.2f} MB** ({file_size_bytes:,} bytes)")
                
                # Verificar limite
                if file_size_mb > 30:
                    add_log("âš ï¸", f"**ALERTA**: Arquivo > 30MB! Cloud Run pode rejeitar.", "warning")
                    add_log("ğŸ’¡", "SoluÃ§Ã£o: Use a versÃ£o local ou divida o arquivo", "warning")
                    
                # Tentar salvar arquivo
                add_log("ğŸ’¾", f"Salvando arquivo no storage...")
                try:
                    file_content = file.read()
                    file.seek(0)  # Resetar para leitura do pandas
                    
                    add_log("â˜ï¸", f"Fazendo upload para Cloud Storage...")
                    
                    saved_path = storage_manager.upload_file(
                        file_content,
                        file.name,
                        folder="uploads"
                    )
                    
                    if not saved_path:
                        add_log("âŒ", f"Erro ao salvar arquivo '{file.name}'", "error")
                        continue
                        
                    add_log("âœ…", f"Arquivo salvo: {saved_path}", "success")
                    
                except Exception as e:
                    add_log("âŒ", f"**ERRO ao salvar**: {str(e)}", "error")
                    add_log("ğŸ”", f"Tipo de erro: {type(e).__name__}", "error")
                    
                    if "413" in str(e) or "Payload" in str(e) or "too large" in str(e).lower():
                        add_log("ğŸš¨", f"**ERRO 413 (Payload Too Large)**", "error")
                        add_log("ğŸ“Š", f"Arquivo {file.name}: {file_size_mb:.2f}MB", "error")
                        add_log("âš ï¸", f"Limite do Cloud Run: ~32MB via HTTP", "error")
                        add_log("ğŸ’¡", f"**SOLUÃ‡ÃƒO**: Use a versÃ£o local:", "warning")
                        add_log("ğŸ’»", "```bash\ngit clone https://github.com/jrbaragao/CRM-IA-VR.git\ncd CRM-IA-VR/vale-refeicao-ia\nstreamlit run app.py\n```", "warning")
                    continue
                
                # Ler arquivo para obter metadados
                add_log("ğŸ“Š", f"Lendo dados para anÃ¡lise...")
                
                try:
                    if file.name.endswith('.csv'):
                        # Ler CSV com tratamento especial para aspas
                        df = pd.read_csv(file, quotechar='"', skipinitialspace=True)
                        # Remover aspas dos nomes das colunas se houver
                        df.columns = df.columns.str.strip('"').str.strip()
                    else:
                        df = pd.read_excel(file)
                    
                    add_log("âœ…", f"Dados lidos: {len(df)} linhas x {len(df.columns)} colunas")
                    
                except Exception as e:
                    add_log("âŒ", f"Erro ao ler dados: {str(e)}", "error")
                    continue
                
                # ValidaÃ§Ãµes bÃ¡sicas
                if df.empty:
                    add_log("âš ï¸", f"Arquivo '{file.name}' estÃ¡ vazio", "warning")
                    continue
                
                # Armazenar no session state
                file_key = f"file_{i}_{file.name}"
                st.session_state['uploaded_files'][file_key] = {
                    'name': file.name,
                    'data': df,  # MantÃ©m em memÃ³ria para preview
                    'file_path': saved_path,  # Caminho no storage
                    'file_size_mb': round(file_size_mb, 2),
                    'type': 'data',  # Todos sÃ£o dados agora
                    'uploaded_at': datetime.now(),
                    'rows': len(df),
                    'columns': len(df.columns),
                    'index_column': None  # Coluna de indexaÃ§Ã£o
                }
                
                add_log("ğŸ‰", f"**Arquivo processado com sucesso!**", "success")
                
            except Exception as e:
                add_log("âŒ", f"**ERRO nÃ£o tratado**: {str(e)}", "error")
                add_log("ğŸ”", f"Tipo de erro: {type(e).__name__}", "error")
                import traceback
                add_log("ğŸ“", f"```\n{traceback.format_exc()}\n```", "error")
        
        progress_bar.progress(1.0)
        add_log("ğŸ", f"**Processamento concluÃ­do!**", "success")
        
        # Resumo final
        successful = len(st.session_state.get('uploaded_files', {}))
        add_log("ğŸ“Š", f"**Total processado**: {successful}/{total_files} arquivo(s)", "success" if successful == total_files else "warning")
        
        # Preview e configuraÃ§Ã£o dos arquivos
        for file_key, file_info in st.session_state['uploaded_files'].items():
            if file_key.startswith('file_'):
                storage_icon = "â˜ï¸" if file_info.get('file_path', '').startswith('gs://') else "ğŸ’¾"
                with st.expander(f"ğŸ“Š {file_info['name']} - {file_info.get('file_size_mb', 0)}MB {storage_icon} ({file_info['rows']} linhas, {file_info['columns']} colunas)", expanded=False):
                    # Preview dos dados
                    st.dataframe(file_info['data'].head(), use_container_width=True)
                    
                    # SeleÃ§Ã£o de coluna de indexaÃ§Ã£o
                    st.divider()
                    col1, col2 = st.columns([1, 1])
                    
                    with col1:
                        st.markdown("**ğŸ”‘ ConfiguraÃ§Ã£o de IndexaÃ§Ã£o**")
                        use_index = st.checkbox(
                            "Definir coluna de indexaÃ§Ã£o",
                            key=f"use_index_{file_key}",
                            help="Marque se deseja definir uma coluna como chave primÃ¡ria/Ã­ndice para correlaÃ§Ã£o entre tabelas"
                        )
                    
                    with col2:
                        if use_index:
                            columns = list(file_info['data'].columns)
                            index_col = st.selectbox(
                                "Selecione a coluna de indexaÃ§Ã£o:",
                                options=[''] + columns,
                                key=f"index_{file_key}",
                                help="Esta coluna serÃ¡ usada como chave primÃ¡ria para relacionar com outras tabelas"
                            )
                            
                            # Atualizar no session state
                            if index_col:
                                st.session_state['uploaded_files'][file_key]['index_column'] = index_col
                                st.info(f"âœ… Coluna '{index_col}' definida como Ã­ndice")
        
    except Exception as e:
        st.error(f"âŒ Erro ao processar arquivos: {str(e)}")

def process_main_file(file):
    """Processa arquivo principal"""
    try:
        # Ler arquivo
        if file.name.endswith('.csv'):
            df = pd.read_csv(file)
        else:
            df = pd.read_excel(file)
        
        # ValidaÃ§Ãµes bÃ¡sicas
        if 'MATRICULA' not in df.columns and 'matricula' not in df.columns and 'Matricula' not in df.columns:
            # Tentar identificar coluna de matrÃ­cula
            possible_matricula_cols = [col for col in df.columns 
                                     if any(term in col.lower() 
                                           for term in ['matric', 'registro', 'cod', 'id'])]
            
            if possible_matricula_cols:
                render_alert(
                    f"Coluna MATRICULA nÃ£o encontrada. PossÃ­veis candidatas: {', '.join(possible_matricula_cols)}",
                    "warning"
                )
            else:
                render_alert(
                    "âš ï¸ AtenÃ§Ã£o: Coluna MATRICULA nÃ£o encontrada. O sistema tentarÃ¡ identificÃ¡-la automaticamente.",
                    "warning"
                )
        
        # Armazenar no session state
        if 'uploaded_files' not in st.session_state:
            st.session_state['uploaded_files'] = {}
        
        st.session_state['uploaded_files']['main'] = {
            'name': file.name,
            'data': df,
            'type': 'main',
            'upload_time': datetime.now(),
            'rows': len(df),
            'columns': len(df.columns)
        }
        
        # Mostrar preview
        render_data_preview(df, f"Preview: {file.name}")
        
        render_alert(f"âœ… Arquivo '{file.name}' carregado com sucesso!", "success")
        
    except Exception as e:
        render_alert(f"Erro ao processar arquivo: {str(e)}", "error")

def process_complementary_files(files):
    """Processa arquivos complementares"""
    if 'uploaded_files' not in st.session_state:
        st.session_state['uploaded_files'] = {}
    
    success_count = 0
    error_count = 0
    
    for file in files:
        try:
            # Ler arquivo
            if file.name.endswith('.csv'):
                # Ler CSV com tratamento especial para aspas
                df = pd.read_csv(file, quotechar='"', skipinitialspace=True)
                # Remover aspas dos nomes das colunas se houver
                df.columns = df.columns.str.strip('"').str.strip()
            else:
                df = pd.read_excel(file)
            
            # Armazenar
            file_key = f"comp_{file.name}"
            st.session_state['uploaded_files'][file_key] = {
                'name': file.name,
                'data': df,
                'type': 'complementary',
                'upload_time': datetime.now(),
                'rows': len(df),
                'columns': len(df.columns)
            }
            
            success_count += 1
            
        except Exception as e:
            error_count += 1
            st.error(f"Erro em '{file.name}': {str(e)}")
    
    if success_count > 0:
        render_alert(
            f"âœ… {success_count} arquivo(s) complementar(es) carregado(s) com sucesso!",
            "success"
        )
    
    if error_count > 0:
        render_alert(
            f"âŒ {error_count} arquivo(s) com erro no processamento.",
            "error"
        )

def process_batch_files(files):
    """Processa mÃºltiplos arquivos em lote"""
    if 'uploaded_files' not in st.session_state:
        st.session_state['uploaded_files'] = {}
    
    progress_bar = st.progress(0, text="Processando arquivos...")
    success_count = 0
    error_count = 0
    
    for idx, file in enumerate(files):
        try:
            # Atualizar progresso
            progress = (idx + 1) / len(files)
            progress_bar.progress(progress, text=f"Processando {file.name}...")
            
            # Ler arquivo
            if file.name.endswith('.csv'):
                # Ler CSV com tratamento especial para aspas
                df = pd.read_csv(file, quotechar='"', skipinitialspace=True)
                # Remover aspas dos nomes das colunas se houver
                df.columns = df.columns.str.strip('"').str.strip()
            else:
                df = pd.read_excel(file)
            
            # Determinar tipo (principal ou complementar)
            file_type = 'main' if idx == 0 else 'complementary'
            file_key = 'main' if file_type == 'main' else f"batch_{file.name}"
            
            # Armazenar
            st.session_state['uploaded_files'][file_key] = {
                'name': file.name,
                'data': df,
                'type': file_type,
                'upload_time': datetime.now(),
                'rows': len(df),
                'columns': len(df.columns)
            }
            
            success_count += 1
            
        except Exception as e:
            error_count += 1
            st.error(f"Erro em '{file.name}': {str(e)}")
    
    progress_bar.empty()
    
    # Mostrar resumo
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Total de Arquivos", len(files))
    with col2:
        st.metric("Sucesso", success_count, delta=None, delta_color="normal")
    with col3:
        st.metric("Erros", error_count, delta=None, delta_color="inverse" if error_count > 0 else "normal")

def display_uploaded_files():
    """Exibe resumo dos arquivos carregados"""
    st.subheader("ğŸ“ Arquivos Carregados")
    
    files_data = []
    total_rows = 0
    
    for key, file_info in st.session_state['uploaded_files'].items():
        files_data.append({
            'Nome': file_info['name'],
            'Tipo': 'Dados',  # Todos sÃ£o dados agora
            'Linhas': f"{file_info['rows']:,}",
            'Colunas': file_info['columns'],
            'Upload': file_info.get('uploaded_at', file_info.get('upload_time', datetime.now())).strftime('%H:%M:%S')
        })
        total_rows += file_info['rows']
    
    # Tabela de arquivos
    df_files = pd.DataFrame(files_data)
    st.dataframe(df_files, use_container_width=True, hide_index=True)
    
    # MÃ©tricas resumidas
    metrics = [
        {'label': 'Total de Arquivos', 'value': len(files_data)},
        {'label': 'Total de Registros', 'value': f"{total_rows:,}"},
        {'label': 'Tabelas a Criar', 'value': len(files_data)}
    ]
    
    render_metrics_row(metrics)
    
    # OpÃ§Ã£o para remover arquivos
    with st.expander("ğŸ—‘ï¸ Gerenciar Arquivos"):
        files_to_remove = st.multiselect(
            "Selecione arquivos para remover:",
            options=[file_info['name'] for file_info in st.session_state['uploaded_files'].values()]
        )
        
        if files_to_remove and st.button("Remover Selecionados", type="secondary"):
            for key, file_info in list(st.session_state['uploaded_files'].items()):
                if file_info['name'] in files_to_remove:
                    del st.session_state['uploaded_files'][key]
            st.rerun()
